---
title: "Introduction to Missing Data Methods Class"
author: "Lecture 1: January 29, 2025" 
format: 
  revealjs:
    multiplex: false
    footer: "[https://jonathantemplin.github.io/MissingDataMethods2025/](https://jonathantemplin.github.io/MissingDataMethods2025/)"
    theme: ["pp.scss"]
    slide-number: c/t
    incremental: false
---

```{r setup, echo=FALSE, include=FALSE}
# clear environment
rm(list=ls())

# load packages

if (!require("lavaan")) install.packages(lavaan)
library(lavaan)
if (!require("ppcor")) install.packages("ppcor")
library(ppcor)

# load iqdata.csv
jobPerf = read.csv("data/jobperf.csv")

# create data sets with each variable using only observed data
jobPerfComplete = jobPerf[c("IQ","perfC")]


jobPerfMCAR = jobPerf[c("IQ","perfMCAR")]
jobPerfMCAR = jobPerfMCAR[complete.cases(jobPerfMCAR),]

jobPerfMAR = jobPerf[c("IQ","perfMAR")]
jobPerfMAR = jobPerfMAR[complete.cases(jobPerfMAR),]

summary(lm(perfC~IQ, data=jobPerfComplete))
summary(lm(perfMCAR~IQ, data=jobPerfMCAR))
summary(lm(perfMAR~IQ, data=jobPerfMAR))
```

## Learning Objectives

1.  Understand the challenges and implications of missing data in research
2.  Classify missing data by patterns and mechanisms using Rubin’s framework
3.  Recognize the limitations of outdated missing data methods
4.  Explore the design and application of planned missing data methods

# Importance of Missing Data

## Why Missing Data Matters

-   Missing data is pervasive across disciplines (e.g., education, psychology, medicine, political science)
-   One big example: Polling errors in elections in 2016/2020 seemed to be affected by missing data (MNAR) - Remedies have been subjective at best
-   Mishandling missing data can:
    -   Bias results --\> Inaccurate conclusions
    -   Reduce statistical power

## Modern Methods

-   **Maximum Likelihood (ML):** Estimates parameters directly from observed data likelihood
-   **Bayesian Estimation:** Combines prior beliefs with data likelihood
-   **Multiple Imputation (MI):** Reflects uncertainty by filling in missing data with plausible values

Additional note: Methods here typically require full-information analyses (i.e., likelihoods based on the data directly)

## Missing Data Patterns vs. Mechanisms

-   A missing data pattern refers to the configuration of observed and missing values in a data set
    -   What you observe in data
-   A missing data mechanism refers to processes that describe different ways in which the probability of missing values relates to the data
    -   Typically untestable
    -   What is assumed about data
-   Patterns describe where the holes are in the data, whereas mech- anisms describe why the values are missing

# Missing Data Patterns

## Types of Missing Data Patterns

::: columns
::: column
-   Univariate
-   Monotone
-   General
-   Planned Missingness
-   Latent Variable
-   Underidentified
:::

::: column
![](img/missing_patterns.png){width="600"}
:::
:::

## Univariate Pattern

-   Missing values restricted to one variable
-   Example: Missing outcomes for some participants

## Monotone Pattern

-   Missing data accumulates predictably
-   Example: Dropout in longitudinal studies
-   Can be treated without complicated iterative estimation algorithms

## General Pattern

-   Missing data scattered randomly across the dataset
-   The three contemporary methods (maximum likelihood, Bayesian estimation, and multiple imputation) work well with this configuration
-   Generally no reason to choose an analytic method based on the missing data pattern alone

## Planned Missingness

-   Variables are intentionally missing for a large proportion of respondents
-   Can reduce respondent burden and research costs
-   Often with minimal impact on statistical power

## Latent Variable Pattern

-   Latent variables are essentially missing data
    -   Presents challenges in secondary analyses
-   Example: Iowa wishes to understand how well an incoming student's ACT score predicts first year GPA
    -   ACT Score: An estimate--not an observation
        -   Can think of scores as single imputation

## Underidentified Pattern

-   Insufficient overlap of data for estimation
-   Example: Sparse cell counts for categorical variables

# Missing Data Mechanisms

## Hypothetical Data Partitioning: Observed Data

::: columns
::: column
-   Before getting to the types of missing data mechanisms, we must first define some notation
-   Our observed data matrix will be defined as $\mathbf{Y}_{(\text{obs})}$
-   Here, $\mathbf{Y}_{(\text{obs})} = \left[Y_1, Y_2, Y_3 \right]$
:::

::: column
![](img/Yobs.png){fig-align="center" width="200"}
:::
:::

## Hypothetical Data Partitioning: Complete Data

::: columns
::: column
-   Imagine if you could somehow see what the values of the missing data were -- the complete data
-   Our hypothetical data matrix will be defined as $\mathbf{Y}_{(\text{com})}$ (sometimes denoted $\mathbf{Y}_{(1)}$)
-   Note: This is not possible through any method and is only a hypothetical example to help define missing data mechanisms
:::

::: column
![](img/Ycom.png){fig-align="center" width="200"}
:::
:::

## Hypothetical Data Partitioning: Missing Data

::: columns
::: column
-   Now, take the values that were missing and only create a matrix of those terms
-   Our hypothetical data matrix will be defined as $\mathbf{Y}_{(\text{mis})}$ (sometimes denoted $\mathbf{Y}_{(0)}$)
-   Note: Again, this is not possible through any method and is only a hypothetical example to help define missing data mechanisms
:::

::: column
![](img/Ymis.png){fig-align="center" width="200"}
:::
:::

## Rubin’s Framework

::: columns
::: column
-   Models that explain whether a participant has missing values
-   How those tendencies relate to the realized data in $\mathbf{Y}_{(\text{obs})}$ or $\mathbf{Y}_{(\text{mis})}$
-   Here,  $\mathbf{M} = \left[M_1, M_2, M_3 \right]$
:::

::: column
![](img/Indicators.png){fig-align="center" width="200"}
:::
:::

## Example Data

::: columns
::: column
* To demonstrate some of the ideas of types of missing data\, let’s consider a situation where you have collected two variables:
  * IQ scores
  * Job performance
* Imagine you are an employer looking to hire employees for a job where IQ is important
:::

::: column
```{r jobPerfData, echo=FALSE}
jobPerf[c("IQ", "perfC")]
```
:::
:::

# Missing Data Mechanisms

## Missing Data Mechanisms

A very rough typology of missing data puts missing observations into three categories:

- Missing Completely At Random \(MCAR\)
- Missing At Random \(MAR\)
- Missing Not At Random \(MNAR\)

## Missing Completely At Random (MCAR)

* Missing data are MCAR if the events that lead to missingness are independent of:
  * The observed variables
  * _\-and\-_
  * The unobserved parameters of interest
* Examples:
  * Planned missingness in survey research
    * Some large\-scale tests are sampled using booklets
    * Students receive only a few of the total number of items
    * The items not received are treated as missing – but that is completely a function of sampling and no other mechanism

## A Formal MCAR Definition

Formally, we note that data are MCAR if the probability of the data being missing is 
independent of the observed data $\mathbf{Y}_{(obs)}$ and the missing data $\mathbf{Y}_{(mis)}$:

$$Pr \left(\mathbf{M} = 1 \mid \mathbf{Y}_{(obs)}, \mathbf{Y}_{(mis)}, \boldsymbol{\phi} \right) = Pr \left(\mathbf{M} = 1 \mid  \boldsymbol{\phi} \right)$$

- Here, $\boldsymbol{\phi}$ are model parameters that define the overall probabilities of missing data
- Like saying a missing observation is due to pure randomness (such as missing if a coin flipped falls on heads)
  
## Implications of MCAR

* Because the mechanism of missing is not due to anything other than chance\, inclusion of MCAR in data will not bias your results
  * Can use methods based on listwise deletion\, multiple imputation\, or maximum likelihood
* Your effective sample size is lowered\, though
  * Less power\, less efficiency

## MCAR Data

::: columns
::: column
Missing data are dispersed randomly throughout data

:::

::: column
```{r jobPerfDataMCAR, echo=FALSE}
jobPerf[c("IQ", "perfMCAR")]
```
:::
:::

## MCAR vs. Complete Data Comparison

::: columns
::: column
Complete Data
```{r, echo=FALSE}

# complete data
completeSyntax = "
IQ ~ 1
perfC ~ 1

IQ ~~ IQ
perfC ~~ perfC

IQ ~~ perfC
"

completeModel = lavaan(model = completeSyntax, data = jobPerfComplete, estimator = "ML")
summary(completeModel, standardized = TRUE)

```
:::

::: column
MAR Data
```{r, echo=FALSE}

# MCAR data
MCARSyntax = "
IQ ~ 1
perfMCAR ~ 1

IQ ~~ IQ
perfMCAR ~~ perfMCAR

IQ ~~ perfMCAR
"

MCARModel = lavaan(model = MCARSyntax, data = jobPerfMCAR, estimator = "ML")
summary(MCARModel, standardized = TRUE)
```
:::
:::

## Missing at Random Definition

Formally, we note that data are MAR if the probability of the data being missing is 
related to the observed data $\mathbf{Y}_{(obs)}$ but not the missing data $\mathbf{Y}_{(mis)}$:

$$Pr \left(\mathbf{M} = 1 \mid \mathbf{Y}_{(obs)}, \mathbf{Y}_{(mis)}, \boldsymbol{\phi} \right) = Pr \left(\mathbf{M} = 1 \mid  \mathbf{Y}_{(obs)}, \boldsymbol{\phi} \right)$$

- Again, $\boldsymbol{\phi}$ are model parameters that define the overall probabilities of missing data
- Like saying a missing observation is due to pure randomness (such as missing if a coin flipped falls on heads)
  

## MAR Data

::: columns
::: column
Missing data are related to other data:

 - Any IQ less than 90 did not have a performance variable
   - Could be that anyone with an IQ of 90 or less was not hired
   - Not hired means not having job performance data


:::

::: column
```{r jobPerfDataMAR, echo=FALSE}
jobPerf[c("IQ", "perfMAR")]
```
:::
:::


## Implications of MAR

* If data are missing at random\, biased results could occur
* Inferences based on listwise deletion will be biased and inefficient
  * Fewer data points = more error in analysis
* Inferences based on maximum likelihood will be unbiased but inefficient
* The first eight chapters of the book focus on methods for MAR data 

## MAR vs. Complete Data Comparison

::: columns
::: column
Complete Data
```{r, echo=FALSE}

# complete data
completeSyntax = "
IQ ~ 1
perfC ~ 1

IQ ~~ IQ
perfC ~~ perfC

IQ ~~ perfC
"

completeModel = lavaan(model = completeSyntax, data = jobPerfComplete, estimator = "ML")
summary(completeModel, standardized = TRUE)

```
:::

::: column
MAR Data
```{r, echo=FALSE}

# MAR data
MARSyntax = "
IQ ~ 1
perfMAR ~ 1

IQ ~~ IQ
perfMAR ~~ perfMAR

IQ ~~ perfMAR
"

MARModel = lavaan(model = MARSyntax, data = jobPerfMAR, estimator = "ML")
summary(MARModel, standardized = TRUE)

```
:::
:::

## Missing Not At Random (MNAR) Definition

Formally, we note that data are MNAR if the probability of the data being missing is 
related to the observed data $\mathbf{Y}_{(obs)}$ and the missing data $\mathbf{Y}_{(mis)}$:

$$Pr \left(\mathbf{M} = 1 \mid \mathbf{Y}_{(obs)}, \mathbf{Y}_{(mis)}, \boldsymbol{\phi} \right)$$

- Again, $\boldsymbol{\phi}$ are model parameters that define the overall probabilities of missing data

Often called non-ignorable missingness

- Inferences based on listwise deletion or maximum likelihood will be biased and inefficient
- Need to provide statistical model for missing data simultaneously with estimation of original model

# Surviving Missing data: A Brief Guide

## Using Statistical Methods with Missing Data

* Missing data can alter your analysis results dramatically depending upon:
  * 1\. The type of missing data
  * 2\. The type of analysis algorithm
* The choice of an algorithm and missing data method is important in avoiding issues due to missing data


## The Worst Case Scenario: MNAR

* The worst case scenario is when data are MNAR: missing not at random
  * Non\-ignorable missing
* You cannot easily get out of this mess
  * Instead you have to be clairvoyant
* Analyses algorithms must incorporate models for missing data
  * And these models must also be right

## The Reality

* In most empirical studies\, MNAR as a condition is an afterthought
* It is impossible to know definitively if data truly are MNAR
  * So data are treated as MAR or MCAR
* Hypothesis tests do exist for MCAR (i.e., Little's test)
  * But, often this test is rejected

## The Best Case Scenario: MCAR

* Under MCAR\, pretty much anything you do with your data will give you the “right” \(unbiased\) estimates of your model parameters
* MCAR is very unlikely to occur
  * In practice\, MCAR is treated as equally unlikely as MNAR


## The Middle Ground: MAR

* MAR is the common compromise used in most empirical research
  * Under MAR\, maximum likelihood algorithms are unbiased
* Maximum likelihood is for many methods:
  * Linear mixed models i
  * Models with “latent” random effects \(CFA/SEM models\) 



# Outdated Methods for Handling Missing Data

## Bad Ways to Handle Missing Data

* Dealing with missing data is important\, as the mechanisms you choose can dramatically alter your results
* This point was not fully realized when the first methods for missing data were created
  * Each of the methods described in this section should  _never be used_
  * Given to show perspective – and to allow you to understand what happens if you were to choose each


## Deletion Methods

* Deletion methods are just that: methods that handle missing data by deleting observations
  * Listwise deletion: delete the entire observation if any values are missing
  * Pairwise deletion: delete a pair of observations if either of the values are missing
* Assumptions: Data are MCAR
* Limitations:
  * Reduction in statistical power if MCAR
  * Biased estimates if MAR or MNAR

## Listwise Deletion


* Listwise deletion discards  _all_  of the data from an observation if one or more variables are missing
* Most frequently used in statistical software packages that are not optimizing a likelihood function \(need ML\)
* In linear models:
  * R lm() list\-wise deletes cases where  __DVs__  are missing

## Listwise Deletion Example: MCAR

::: columns
::: column
```{r, echo=FALSE}
# listwise deletion example
listCompleteSyntax = "

perfC ~ 1 + IQ
perfC ~~ perfC

"

listCompleteModel = lavaan(model = listCompleteSyntax, data = jobPerfComplete, estimator = "ML")
summary(listCompleteModel, header=FALSE)
```
:::

::: column
```{r, echo=FALSE}
listMCARSyntax = "

perfMCAR ~ 1 + IQ
perfMCAR ~~ perfMCAR

"

listMCARModel = lavaan(model = listMCARSyntax, data = jobPerfMCAR, estimator = "ML")
summary(listMCARModel, header=FALSE)
```
:::
:::

## Listwise Deletion Example: MAR


::: columns
::: column
```{r, echo=FALSE}
# listwise deletion example
listCompleteSyntax = "

perfC ~ 1 + IQ
perfC ~~ perfC

"

listCompleteModel = lavaan(model = listCompleteSyntax, data = jobPerfComplete, estimator = "ML")
summary(listCompleteModel, header=FALSE)
```
:::

::: column
```{r, echo=FALSE}

listMARSyntax = "

perfMAR ~ 1 + IQ
perfMAR ~~ perfMAR

"

listMARModel = lavaan(model = listMARSyntax, data = jobPerfMAR, estimator = "ML")
summary(listMARModel, header=FALSE)

```

:::
:::

## Pairwise Deletion

* Pairwise deletion discards a pair of observations if either one is missing
  * Different from listwise: uses more data \(rest of data not thrown out\)
* Assumes: MCAR
* Limitations:
  * Reduction in statistical power if MCAR
  * Biased estimates if MAR or MNAR
* Can be an issue when forming covariance/correlation matrices
  * May make them non\-invertible\, problem if used as input into statistical procedures


## Pairwise Deletion Example

```{r, echo=TRUE}
cor(jobPerf, use="pairwise.complete.obs")

```


## Single Imputation Methods

* __Single imputation __ methods replace missing data with some type of value
  * _Single:_  one value used
  * _Imputation:_  replace missing data with value
* Upside: can use entire data set if missing values are replaced
* Downside: biased parameter estimates and standard errors \(even if missing is MCAR\)
  * Type\-I error issues
* Still: never use these techniques

## Unconditional Mean Imputation

* Unconditional mean imputation replaces the missing values of a variable with its estimated mean
  * Unconditional  = mean value without any input from other variables

## Unconditional Mean Imputation: MCAR Data vs Complete Data

```{r, echo=FALSE, include=FALSE, eval=TRUE}
# take MCAR data and impute mean for all missing cases
jobPerf$perfMCAR_meanImpute = jobPerf$perfMCAR
jobPerf$perfMCAR_meanImpute[is.na(jobPerf$perfMCAR_meanImpute)] = mean(jobPerf$perfMCAR_meanImpute, na.rm = TRUE)

# take MAR data and impute mean for all missing cases
jobPerf$perfMAR_meanImpute = jobPerf$perfMAR
jobPerf$perfMAR_meanImpute[is.na(jobPerf$perfMAR_meanImpute)] = mean(jobPerf$perfMAR_meanImpute, na.rm = TRUE)

```

::: columns
::: column
Complete
```{r}
summary(lm(perfC~IQ, data=jobPerf))
```
:::

::: column
MCAR
```{r}
summary(lm(perfMCAR_meanImpute~IQ, data=jobPerf))
```
:::
:::

## Unconditional Mean Imputation: MAR Data vs Complete Data

::: columns
::: column
Complete
```{r}
summary(lm(IQ~perfC, data=jobPerf))
```
:::

::: column
MAR
```{r}
summary(lm(IQ~perfMAR_meanImpute, data=jobPerf))
```
:::
:::

# Conditional Mean Imputation (Regression)



* Conditional mean imputation uses regression analyses to impute missing values
  * The missing values are imputed using the predicted values in each regression \(conditional means\)
* For our data we would form regressions for each outcome using the other variables
  * PERF = β01 \+ β11\*IQ 
* More accurate than unconditional mean imputation
  * But still provides biased parameters and SEs


# Stochastic Conditional Mean Imputation

- Stochastic conditional mean imputation adds a random component to the imputation
  - Representing the error term in each regression equation
  - Assumes MAR rather than MCAR
- Better than any other of these methods (and the basis for multiple imputation)

# Imputation by Proximity: Hot Deck Matching



* Hot deck matching uses real data – from other observations as its basis for imputing
* Observations are “matched” using similar scores on variables in the data set
  * Imputed values come directly from matched observations
* Upside: Helps to preserve univariate distributions; gives data in an appropriate range
* Downside: biased estimates \(especially of regression coefficients\)\, too\-small standard errors


# Scale Imputation by Averaging



* In psychometric tests\, a common method of imputation has been to use a scale average rather than total score
  * Can re\-scale to total score by taking \# items \* average score
* Problem: treating missing items this way is like using person mean
  * Reduces standard errors
  * Makes calculation of reliability biased


# Longitudinal Imputation: Last Observation Carried Forward



* A commonly used imputation method in longitudinal data has been to treat observations that dropped out by carrying forward thelast observation
  * More common in medical studies and clinical trials
* Assumes scores do not change after dropout – bad idea
  * Thought to be conservative
* Can exaggerate group differences
  * Limits standard errors that help detect group differences

# Why Single Imputation Is Bad Science



* Overall\, the methods described in this section are not useful for handling missing data
* If you use them you will likely get a statistical answer that is an artifact
  * Actual estimates you interpret \(parameter estimates\) will be biased \(in either direction\)
  * Standard errors will be too small
    * Leads to Type\-I Errors
* Putting this together: you will likely end up making conclusions about your data that are wrong



# Auxiliary Variables and Semi-Partial Correlation

## Auxiliary Variables and Semi-Partial Correlation

The use of **auxiliary variables** can help mitigate bias and improve statistical power when missing data are present

- An auxiliary variable is an extraneous variable that correlates with missingness or the outcome but is not part of the main analysis

A key aspect of auxiliary variable selection is understanding their **semi-partial correlation** with the outcome

- Semi-partial correlation quantifies the unique contribution of a predictor to the outcome, after removing its shared variance with other predictors
- This makes Semi-partial correlations useful for identifying the most informative auxiliary variables

# What is a Semi-Partial Correlation?

- **Semi-partial correlation** (also known as part correlation) measures the unique association between a predictor and the outcome while controlling for other variables in the model
- Unlike **partial correlation**, which removes shared variance from both variables, semi-partial correlation removes shared variance only from the predictor variable, leaving the outcome variable unchanged

# What is a Semi-Partial Correlation?

Mathematically, the semi-partial correlation of a predictor $( X_1 )$ with an outcome $(Y)$, controlling for another predictor $X_2$, is given by:


$$ r_{Y(X_1.X_2)} = \frac{r_{YX_1} - r_{YX_2}r_{X_1X_2}}{\sqrt{1 - r_{X_1X_2}^2}} $$

where:
- $r_{YX_1}$is the correlation between $Y$ and $X_1$,
- $r_{YX_2}$ is the correlation between $Y$ and $X_2$,
- $r_{X_1X_2}$ is the correlation between $X_1$ and $X_2$.

## Why is Semi-Partial Correlation Important?

Semi-partial correlation is widely used in statistics for several reasons:

1. **Understanding Unique Contributions** – It helps to determine how much unique variance a predictor explains in the outcome, which is useful in multiple regression and hierarchical modeling
2. **Feature Selection** – In machine learning and predictive modeling, semi-partial correlation can help identify the most important predictors
3. **Model Interpretation** – Researchers can use it to assess the relative importance of predictors in explaining variance in an outcome
4. **Comparing Predictors** – It allows us to compare multiple predictors to see which has the most unique explanatory power

Because semi-partial correlation removes shared variance only from the predictor, it reflects the real-world scenario where some predictors contribute uniquely to an outcome while sharing variance with others. 

## Semi-Partial Correlation in the Context of Missing Data

- Semi-partial correlations help identify which auxiliary variables provide unique information about missingness or the outcome
  - This ensures that missing data handling methods, such as multiple imputation or maximum likelihood estimation, make the most use of available information

# Example in R

## Simulated Data
Let's create a dataset where we examine semi-partial correlations:

```{r, echo=TRUE}
set.seed(42)
n = 100
y = rnorm(n, mean=50, sd=10)   # Outcome variable
x1 = rnorm(n, mean=10, sd=5)    # Predictor 1
x2 = rnorm(n, mean=20, sd=5)    # Predictor 2
aux = .05*y + 0.5*x1 + 0.3*x2 + rnorm(n, mean=0, sd=2)  # Auxiliary variable

data = data.frame(y, x1, x2, aux)
```

## Computing Semi-Partial Correlation using lm() residuals
```{r, echo=TRUE}
# Step 1: Regress the auxiliary variable on other predictors and obtain residuals
aux_resid = resid(lm(aux ~ x1 + x2, data=data))

# Step 2: Compute the correlation between residuals and the outcome
spr_lm = cor(aux_resid, data$y)
print(spr_lm)
```

## Computing Semi-Partial Correlation using the `ppcor` package
```{r, echo=TRUE} 

# Compute semi-partial correlation using spcorr package
spr_spcorr = spcor(data)
print(spr_spcorr)
```

# Comparison of Results

Both methods should yield similar results, but `spcor` provides a more automated way to compute semi-partial correlations, making it easier to handle multiple predictors at once. 

- But, 'spcor' doesn't have the ability to specify certain combinations of variables

Interpretation:

- If the semi-partial correlation is strong (e.g., above 0.30 in absolute value), the auxiliary variable is likely to contain unique information about the outcome and should be included in the missing data handling process


# Wrapping Up

# Lecture Summary

* Missing data are common in statistical analyses
* They are frequently neglected
  * MNAR: hard to model missing data and observed data simultaneously
  * MCAR: doesn’t often happen
  * MAR: most missing imputation assumes MVN
* More often than not\, ML is the best choice
  * Software is getting better at handling missing data
  * We will discuss how ML works next week
